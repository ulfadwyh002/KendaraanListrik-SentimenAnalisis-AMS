{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PROSES PENGAMBILAN VIDEO"
      ],
      "metadata": {
        "id": "KhtuoxWQk5oL"
      },
      "id": "KhtuoxWQk5oL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam proses pengambilan data, kami menggunakan YouTube API dengan memasukkan beberapa keyword yang relevan dengan topik analisis. Setelah itu, sistem menampilkan sejumlah video yang sesuai dengan keyword tersebut. Dari hasil tersebut, kami tidak mengambil semua video, melainkan hanya memilih beberapa video secara selektif. Pemilihan ini didasarkan pada kriteria tertentu, seperti jumlah like, view, isi komentar yang bervariasi, dan relevansi komentar terhadap isu yang sedang diteliti. Tujuan dari penyaringan ini adalah untuk memperoleh data komentar yang lebih kaya secara konteks dan sesuai dengan fokus analisis yang telah ditetapkan."
      ],
      "metadata": {
        "id": "4_sCV4hjk9AN"
      },
      "id": "4_sCV4hjk9AN"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f5d874eb",
      "metadata": {
        "id": "f5d874eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab2d166-2e94-4c13-91b6-85866e277790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.176.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.7.14)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-api-python-client\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TAHAP 1"
      ],
      "metadata": {
        "id": "4lei9zx2kxwP"
      },
      "id": "4lei9zx2kxwP"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "192f58b5",
      "metadata": {
        "id": "192f58b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7572aa-33d9-4464-a75e-39d8f9ee9f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ditemukan 7 video untuk keyword 'kelemahan dan kelebihan kendaraan listrik'\n",
            "Ditemukan 7 video untuk keyword 'Kendaraan listrik ramah lingkungan'\n",
            "Ditemukan 7 video untuk keyword 'subsidi pemerintah untuk kendaraan listrik: layak atau tidak?'\n",
            "Ditemukan 21 video untuk keyword '['kelemahan dan kelebihan kendaraan listrik', 'Kendaraan listrik ramah lingkungan', 'subsidi pemerintah untuk kendaraan listrik: layak atau tidak?']'\n",
            "{'R55pRFBDyAI', 'nTDLDK6UlzI', '8FVOLVfGgZ0', '3NcRyVgFlnU', '3vd5WAFW9i8', '6MmqTocDXPg', 'Obajud-tLwg', 'sVwttNtOgv0', 'l2MwqYjmVSY', 'vqCLNSNDu6c', 'xcDZaMW8Se8', 'tw7c7Iv2DSo', '50KZ16zj5LE', 'kv_HRNPpq2c', 'E2QS4p3zFvQ', '44iENKIM14k', 'MbhVp8btNgE', 'v6tgbL_Acs8', 'Xe2Dp3WODMk', '6RCfwZqqQeY', 'noltRzcuXSI'}\n",
            "Mengambil data video: R55pRFBDyAI\n",
            "Mengambil data video: nTDLDK6UlzI\n",
            "Mengambil data video: 8FVOLVfGgZ0\n",
            "Mengambil data video: 3NcRyVgFlnU\n",
            "Mengambil data video: 3vd5WAFW9i8\n",
            "Mengambil data video: 6MmqTocDXPg\n",
            "Mengambil data video: Obajud-tLwg\n",
            "Mengambil data video: sVwttNtOgv0\n",
            "Mengambil data video: l2MwqYjmVSY\n",
            "Mengambil data video: vqCLNSNDu6c\n",
            "Mengambil data video: xcDZaMW8Se8\n",
            "Mengambil data video: tw7c7Iv2DSo\n",
            "Mengambil data video: 50KZ16zj5LE\n",
            "Mengambil data video: kv_HRNPpq2c\n",
            "Mengambil data video: E2QS4p3zFvQ\n",
            "Mengambil data video: 44iENKIM14k\n",
            "Mengambil data video: MbhVp8btNgE\n",
            "Mengambil data video: v6tgbL_Acs8\n",
            "Mengambil data video: Xe2Dp3WODMk\n",
            "Mengambil data video: 6RCfwZqqQeY\n",
            "Mengambil data video: noltRzcuXSI\n",
            "✅ Data disimpan ke file Excel: Data Awal kendaraan listrik.xlsx\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# === KONFIGURASI ===\n",
        "api_key = 'AIzaSyDG0E9CNV_5yK1E_FUFdcAuBh0t6JMV6jI'\n",
        "keywords = ['kelemahan dan kelebihan kendaraan listrik', 'Kendaraan listrik ramah lingkungan', 'subsidi pemerintah untuk kendaraan listrik: layak atau tidak?']\n",
        "max_results = 7 # maksimal 7\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "video_info_list = []\n",
        "top_comments = []\n",
        "replies = []\n",
        "\n",
        "# === FUNGSI ===\n",
        "def search_videos_by_keyword(keywords, max_results=5):\n",
        "    video_ids = []\n",
        "    for keyword in keywords:\n",
        "        search_response = youtube.search().list(\n",
        "            q=keyword,\n",
        "            part='id',\n",
        "            type='video',\n",
        "            maxResults=max_results\n",
        "        ).execute()\n",
        "        video_ids_temp = [\n",
        "            item['id']['videoId']\n",
        "            for item in search_response.get('items', [])\n",
        "            if 'videoId' in item.get('id', {})\n",
        "        ]\n",
        "        video_ids = video_ids + video_ids_temp\n",
        "        print(f\"Ditemukan {len(video_ids_temp)} video untuk keyword '{keyword}'\")\n",
        "    return set(video_ids)\n",
        "\n",
        "\n",
        "def get_video_info(video_id):\n",
        "    response = youtube.videos().list(\n",
        "        part='snippet,statistics',\n",
        "        id=video_id\n",
        "    ).execute()\n",
        "\n",
        "    if not response['items']:\n",
        "        return {}\n",
        "\n",
        "    item = response['items'][0]\n",
        "    snippet = item['snippet']\n",
        "    stats = item['statistics']\n",
        "\n",
        "    return {\n",
        "        'video_id': video_id,\n",
        "        'title': snippet.get('title'),\n",
        "        'description': snippet.get('description'),\n",
        "        'uploader': snippet.get('channelTitle'),\n",
        "        'upload_date': snippet.get('publishedAt'),\n",
        "        'view_count': stats.get('viewCount'),\n",
        "        'like_count': stats.get('likeCount'),\n",
        "        'comment_count': stats.get('commentCount')\n",
        "    }\n",
        "\n",
        "def get_all_replies(parent_id):\n",
        "    all_replies = []\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        response = youtube.comments().list(\n",
        "            part=\"snippet\",\n",
        "            parentId=parent_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        ).execute()\n",
        "\n",
        "        for r in response.get(\"items\", []):\n",
        "            s = r['snippet']\n",
        "            all_replies.append({\n",
        "                'reply_id': r['id'],\n",
        "                'parent_id': parent_id,\n",
        "                'author': s.get('authorDisplayName'),\n",
        "                'text': s.get('textOriginal'),\n",
        "                'likes': s.get('likeCount'),\n",
        "                'published': s.get('publishedAt'),\n",
        "                'updated': s.get('updatedAt')\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "    return all_replies\n",
        "\n",
        "def get_all_comments(video_id, cek_replies = True):\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part='snippet',\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat='plainText'\n",
        "        ).execute()\n",
        "\n",
        "        for item in response.get(\"items\", []):\n",
        "            try:\n",
        "                top = item['snippet']['topLevelComment']\n",
        "                s = top['snippet']\n",
        "                comment_id = top['id']\n",
        "\n",
        "                top_comment_data = {\n",
        "                    'comment_id': comment_id,\n",
        "                    'video_id': video_id,\n",
        "                    'author': s.get('authorDisplayName'),\n",
        "                    'text': s.get('textOriginal'),\n",
        "                    'likes': s.get('likeCount'),\n",
        "                    'published': s.get('publishedAt'),\n",
        "                    'updated': s.get('updatedAt')\n",
        "                }\n",
        "                top_comments.append(top_comment_data)\n",
        "                if cek_replies:\n",
        "                    all_r = get_all_replies(comment_id)\n",
        "                    replies.extend(all_r)\n",
        "\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "# === PROSES UTAMA ===\n",
        "video_ids = search_videos_by_keyword(keywords, max_results=max_results)\n",
        "print(f\"Ditemukan {len(video_ids)} video untuk keyword '{keywords}'\")\n",
        "print(video_ids)\n",
        "for vid in video_ids:\n",
        "    try:\n",
        "        print(f\"Mengambil data video: {vid}\")\n",
        "        info = get_video_info(vid)\n",
        "        if info:\n",
        "            video_info_list.append(info)\n",
        "            get_all_comments(vid, cek_replies=False) # cek_replies=True, Jika ingin mengambil data balasan komen\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat memproses video {vid}: {e}\")\n",
        "\n",
        "# === SIMPAN KE EXCEL ===\n",
        "df_video = pd.DataFrame(video_info_list)\n",
        "df_top = pd.DataFrame(top_comments)\n",
        "df_replies = pd.DataFrame(replies)\n",
        "\n",
        "output_file = \"Data Awal kendaraan listrik.xlsx\"\n",
        "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "    df_video.to_excel(writer, sheet_name='VideoInfo', index=False)\n",
        "    df_top.to_excel(writer, sheet_name='TopComments', index=False)\n",
        "    # df_replies.to_excel(writer, sheet_name='Replies', index=False) # aktifkan Jika ingin menyimpan data balasan komen\n",
        "\n",
        "print(f\"✅ Data disimpan ke file Excel: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6d0e06e2",
      "metadata": {
        "id": "6d0e06e2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Baca file Excel\n",
        "file_path = output_file\n",
        "\n",
        "# Baca masing-masing sheet ke DataFrame\n",
        "df_video = pd.read_excel(file_path, sheet_name='VideoInfo')\n",
        "df_top = pd.read_excel(file_path, sheet_name='TopComments')\n",
        "# df_replies = pd.read_excel(file_path, sheet_name='Replies') # aktifkan Jika sebelumnya menyimpan data balasan komen"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TAHAP 2\n",
        "\n"
      ],
      "metadata": {
        "id": "Oz9LRerJjQFT"
      },
      "id": "Oz9LRerJjQFT"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f940e6ae",
      "metadata": {
        "id": "f940e6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6894a75a-3f67-4425-db18-7d59e6f18f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Mengambil data video dan komentar...\n",
            "Menyimpan ke file Excel (.xlsx)...\n",
            "Selesai! File disimpan sebagai:\n",
            "- youtube_videos.xlsx (info video)\n",
            "- youtube_comments.xlsx (komentar dan balasan lengkap)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "!pip install openpyxl\n",
        "\n",
        "\n",
        "\n",
        "# Inisialisasi YouTube API\n",
        "youtube = build('youtube', 'v3', developerKey='AIzaSyDG0E9CNV_5yK1E_FUFdcAuBh0t6JMV6jI')\n",
        "\n",
        "def get_video_info(video_ids):\n",
        "    response = youtube.videos().list(\n",
        "        part='snippet,statistics',\n",
        "        id=','.join(video_ids),\n",
        "        maxResults=50\n",
        "    ).execute()\n",
        "\n",
        "    results = []\n",
        "    for item in response.get('items', []):\n",
        "        snippet = item['snippet']\n",
        "        stats = item['statistics']\n",
        "        results.append({\n",
        "            'video_id': item['id'],\n",
        "            'title': snippet.get('title'),\n",
        "            'description': snippet.get('description'),\n",
        "            'channel': snippet.get('channelTitle'),\n",
        "            'published_at': snippet.get('publishedAt'),\n",
        "            'views': stats.get('viewCount', 0),\n",
        "            'likes': stats.get('likeCount', 0),\n",
        "            'comments': stats.get('commentCount', 0),\n",
        "            'channel_id': snippet.get('channelId')\n",
        "        })\n",
        "    return results\n",
        "\n",
        "def get_all_comments(video_ids, include_replies=True):\n",
        "    comments = []\n",
        "    replies = []\n",
        "\n",
        "    for video_id in video_ids:\n",
        "        try:\n",
        "            next_page_token = None\n",
        "            while True:\n",
        "                response = youtube.commentThreads().list(\n",
        "                    part='snippet',\n",
        "                    videoId=video_id,\n",
        "                    maxResults=100,\n",
        "                    pageToken=next_page_token,\n",
        "                    textFormat='plainText'\n",
        "                ).execute()\n",
        "\n",
        "                for item in response['items']:\n",
        "                    top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "                    comments.append({\n",
        "                        'comment_id': item['id'],\n",
        "                        'video_id': video_id,\n",
        "                        'author': top_comment.get('authorDisplayName'),\n",
        "                        'likes': top_comment.get('likeCount', 0),\n",
        "                        'published': top_comment.get('publishedAt'),\n",
        "                        'updated': top_comment.get('updatedAt', top_comment.get('publishedAt')),  # fallback\n",
        "                        'text': top_comment.get('textOriginal'),\n",
        "                        'teks_new': preprocess_text(top_comment.get('textOriginal')),\n",
        "                        'teks_new_lower': preprocess_text(top_comment.get('textOriginal')).lower()\n",
        "                    })\n",
        "\n",
        "                    if include_replies and item['snippet']['totalReplyCount'] > 0:\n",
        "                        reply_data = get_replies(item['id'], video_id)\n",
        "                        replies.extend(reply_data)\n",
        "\n",
        "                next_page_token = response.get('nextPageToken')\n",
        "                if not next_page_token:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {video_id}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return comments + replies\n",
        "\n",
        "def get_replies(parent_id, video_id):\n",
        "    replies = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            response = youtube.comments().list(\n",
        "                part='snippet',\n",
        "                parentId=parent_id,\n",
        "                maxResults=100,\n",
        "                pageToken=next_page_token,\n",
        "                textFormat='plainText'\n",
        "            ).execute()\n",
        "\n",
        "            for item in response['items']:\n",
        "                reply = item['snippet']\n",
        "                replies.append({\n",
        "                    'comment_id': item['id'],\n",
        "                    'video_id': video_id,\n",
        "                    'author': reply.get('authorDisplayName'),\n",
        "                    'likes': reply.get('likeCount', 0),\n",
        "                    'published': reply.get('publishedAt'),\n",
        "                    'updated': reply.get('updatedAt', reply.get('publishedAt')),\n",
        "                    'text': reply.get('textOriginal'),\n",
        "                    'teks_new': preprocess_text(reply.get('textOriginal')),\n",
        "                    'teks_new_lower': preprocess_text(reply.get('textOriginal')).lower()\n",
        "                })\n",
        "\n",
        "            next_page_token = response.get('nextPageToken')\n",
        "            if not next_page_token:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting replies for {parent_id}: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    return replies\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if text is None:\n",
        "        return ''\n",
        "    return text.strip()\n",
        "\n",
        "# Video ID\n",
        "video_ids = ['pxmq9yyOjo0','UYXcAnb1mV8', '0fzwRDVdkC4', 'zOqALVotnRs', 'kv_HRNPpq2c', '8FVOLVfGgZ0', '50KZ16zj5LE']\n",
        "\n",
        "# Ambil data\n",
        "print(\"Mengambil data video dan komentar...\")\n",
        "video_data = get_video_info(video_ids)\n",
        "all_comments = get_all_comments(video_ids)\n",
        "\n",
        "# Simpan ke XLSX\n",
        "print(\"Menyimpan ke file Excel (.xlsx)...\")\n",
        "pd.DataFrame(video_data).to_excel('Data_youtube_videos.xlsx', index=False)\n",
        "pd.DataFrame(all_comments).to_excel('Data_youtube_comments.xlsx', index=False)\n",
        "\n",
        "print(\"Selesai! File disimpan sebagai:\")\n",
        "print(\"- youtube_videos.xlsx (info video)\")\n",
        "print(\"- youtube_comments.xlsx (komentar dan balasan lengkap)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}